
---

<div align="center">

# ğŸ§  **deepthon**
### *A Minimal Deep Learning Framework Built from Scratch with NumPy*

## **Research-oriented â€¢ Transparent â€¢ Mathematical â€¢ Lightweight**


[![NumPy](https://img.shields.io/badge/Built%20with-NumPy-blue?style=for-the-badge)](https://numpy.org)
[![License](https://img.shields.io/badge/license-MIT-green?style=for-the-badge)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Research--Grade-orange?style=for-the-badge)](#)
[![Stars](https://img.shields.io/github/stars/Ibraheem-Al-hafith/deepthon?style=social)](https://github.com/Ibraheem-Al-hafith/deepthon)

<img src="./assets/header.png" width="50%" height="50%" style="border-radius:10% "/>

</div>

---

# ğŸ“œ Abstract

**deepthon** is a **from-scratch neural network framework** implemented using only **NumPy**.  
It is designed to serve as a **research, educational, and experimental platform** for understanding the internal mechanics of modern deep learning systems.

Unlike PyTorch or TensorFlow, **deepthon exposes the mathematics** behind:
- Forward propagation  
- Loss computation  
- Backpropagation  
- Gradient-based optimization  

> deepthon treats neural networks not as black boxes, but as **numerical systems**.

---

# ğŸ§¬ Motivation

Modern deep learning frameworks hide critical details behind automatic differentiation and optimized kernels.  
This is excellent for productionâ€”but terrible for **learning, theory, and research debugging**.

deepthon was created to answer:
> *â€œWhat actually happens when a neural network trains?â€*

deepthon allows you to:
- Inspect gradients
- Modify the learning rule
- Inject custom math
- Perform controlled experiments



---

# âœ¨ Features

| Category | Capabilities |
|--------|--------------|
| ğŸ§  Models | `Sequential` API, fully modular layers |
| ğŸ”¢ Math | Manual forward & backward propagation |
| âš¡ Optimization | SGD, Adam, RMSProp, LR schedulers |
| ğŸ“‰ Losses | MSE, BCE, Cross-Entropy |
| ğŸ“Š Metrics | Accuracy, Precision, Recall |
| ğŸ§ª Experiments | Validation, metrics, training history |
| ğŸª¶ Dependencies | NumPy only |


---


Each component is mathematically isolated and explicitly implemented.

---

# ğŸ“¦ Installation
**uv installation**

* 1. Download and build the dependencies:

```bash
git clone https://github.com/Ibraheem-Al-hafith/deepthon
cd deepthon
uv sync

```

* 2. Activate the environment:
> A. for windows:

```
.venv/Scripts/activate

```
> B. for mac/linux

```
.venv/bin/activate

```

---

# ğŸš€ Minimal Experiment
**(note): you can check examples in [examples](/examples), see the next section**

```python
import numpy as np
from deepthon.nn import Sequential, Layer
from deepthon.nn.activations import ReLU, Sigmoid
from deepthon.nn.losses import BCE
from deepthon.nn.optimizers import Adam
from deepthon.pipeline import Trainer

X = np.random.randn(500, 2)
y = (X[:, 0] * X[:, 1] > 0).astype(float).reshape(-1, 1)

model = Sequential([
    Layer(2, 16, activation=ReLU()),
    Layer(16, 8, activation=ReLU()),
    Layer(8, 1, activation=Sigmoid())
])

trainer = Trainer(
    model=model,
    optimizer=Adam(lr=1e-3),
    loss_func=BCE(),
    batch_size=32,
    metric_fn="accuracy"
)

trainer.train(X, y, epochs=30)
```

# run examples :

### run simple `sklearn` circles dataset experiment:

```
uv run examples/circles_classification.py

```

---


Tracks:

* Loss
* Accuracy
* Validation metrics
* Learning rate

---

# ğŸ—‚ Codebase

```
deepthon/
â”‚
â”œâ”€â”€ nn/           # layers, activations, losses, optimizers
â”œâ”€â”€ pipeline/     # Trainer & training loops
â”œâ”€â”€ utils/        # metrics, helpers
```

---

# ğŸ”¬ Research Use Cases

deepthon is ideal for:

* Studying optimization dynamics
* Testing new learning rules
* Verifying gradient correctness
* Teaching deep learning
* Writing academic experiments

---

# ğŸ§  Comparison

| Feature      | deepthon  | PyTorch  |
| ------------ | --------- | -------- |
| Autograd     | âŒ No (coming soon)     | âœ… Yes    |
| Transparency | â­â­â­â­â­     | â­â­       |
| Debugging    | Easy      | Hard     |
| Learning     | Excellent | Moderate |
| GPU          | âŒ No (coming soon)     | âœ… Yes    |

---

# ğŸ›£ Roadmap
```
ğŸ”¹ CNN & Dropout
ğŸ”¹ Visualization dashboard
ğŸ”¹ Model serialization
ğŸ”¹ Jupyter tutorials
ğŸ”¹ CuPy GPU backend
```
---

# ğŸ“„ License

MIT License

---

<div align="center">

ğŸ§  **deepthon** â€” Where deep learning meets mathematics
Built by **Ibraheem Al-Hafith**

</div>
```

