{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f87c1cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e8e54c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., 0., 0.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 0., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1.],\n",
       "       [1., 0., 1., 1., 1.],\n",
       "       [1., 0., 1., 0., 1.],\n",
       "       [0., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 0., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = (np.random.rand(10, 5) > 0.2).astype(np.float32)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a4c5504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0],\n",
       "       [0, 2, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 3]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = [1, 2, 1, 1, 3]\n",
    "np.diag(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f88bf0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 1, 1, 3],\n",
       "       [2, 4, 2, 2, 6],\n",
       "       [1, 2, 1, 1, 3],\n",
       "       [1, 2, 1, 1, 3],\n",
       "       [3, 6, 3, 3, 9]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.outer(m, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3bb153f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, -2, -1, -1, -3],\n",
       "       [-2, -2, -2, -2, -6],\n",
       "       [-1, -2,  0, -1, -3],\n",
       "       [-1, -2, -1,  0, -3],\n",
       "       [-3, -6, -3, -3, -6]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(m) - np.outer(m, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8c31df1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Matrix:\n",
      "[[0.19331988 0.0457593  0.37342652 0.38749429]\n",
      " [0.03424102 0.1335862  0.31643557 0.51573721]\n",
      " [0.29352668 0.2982287  0.15553784 0.25270678]]\n",
      "\n",
      "Row Sums Check:\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_prob_matrix(rows, cols):\n",
    "    random_matrix = np.random.rand(rows, cols)\n",
    "    row_sums = random_matrix.sum(axis=1, keepdims=True)\n",
    "    probability_matrix = random_matrix / row_sums\n",
    "    return probability_matrix\n",
    "\n",
    "# Example usage:\n",
    "matrix = generate_prob_matrix(3, 4)\n",
    "print(\"Generated Matrix:\")\n",
    "print(matrix)\n",
    "print(\"\\nRow Sums Check:\")\n",
    "print(matrix.sum(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "90a1e5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d5dfd5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02163613, -0.00869798,  0.0009184 , -0.01385654],\n",
       "       [-0.02346224,  0.05889068, -0.01225177, -0.02317667],\n",
       "       [ 0.00285497,  0.04368378, -0.023314  , -0.02322475]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((matrix.reshape(3, 4, 1) * np.eye(4)) - (matrix.reshape(3, 4, 1) @ matrix.reshape(3, 1, 4))) @ matrix.reshape(3, 4, 1)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1d16eb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Forward Pass ---\n",
      "Loss: 1.483649\n",
      "\n",
      "--- Probabilities (P) Matrix (Shape (10, 4)) ---\n",
      "[[0.18235934 0.09664077 0.21207787 0.50892203]\n",
      " [0.09213474 0.09213625 0.56488278 0.25084624]\n",
      " [0.1735804  0.47755308 0.17463491 0.17423161]]\n",
      "\n",
      "--- Gradient (dL/dX) Matrix (Shape (10, 4)) ---\n",
      "[[ 0.01823593  0.00966408 -0.07879221  0.0508922 ]\n",
      " [ 0.00921347 -0.09078637  0.05648828  0.02508462]\n",
      " [ 0.01735804 -0.05224469  0.01746349  0.01742316]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(X):\n",
    "    \"\"\"\n",
    "    Computes the softmax of each row of the input X.\n",
    "    Incorporates numerical stability by subtracting the max logit.\n",
    "    \"\"\"\n",
    "    # X shape: (M, C)\n",
    "    shift_x = X - np.max(X, axis=1, keepdims=True)\n",
    "    exps = np.exp(shift_x)\n",
    "    return exps / np.sum(exps, axis=1, keepdims=True)\n",
    "\n",
    "def cross_entropy_loss(P, Y):\n",
    "    \"\"\"\n",
    "    Computes the mean cross-entropy loss over the batch.\n",
    "    L = -1/M * sum(sum(Y * log(P)))\n",
    "    \"\"\"\n",
    "    M = Y.shape[0]\n",
    "    # Small epsilon to prevent log(0)\n",
    "    epsilon = 1e-12\n",
    "    log_p = np.log(P + epsilon)\n",
    "    loss = -np.sum(Y * log_p) / M\n",
    "    return loss\n",
    "\n",
    "def compute_gradients(P, Y):\n",
    "    \"\"\"\n",
    "    Computes the gradient of the loss w.r.t the logits X.\n",
    "    dL/dX = 1/M * (P - Y)\n",
    "    \"\"\"\n",
    "    M = Y.shape[0]\n",
    "    return (P - Y) / M\n",
    "\n",
    "# --- Execution & Synthetic Data Generation ---\n",
    "\n",
    "# 1. Setup Hyperparameters\n",
    "M, C = 10, 4\n",
    "np.random.seed(42)\n",
    "\n",
    "# 2. Generate Synthetic Data\n",
    "# Logits (X) from a normal distribution\n",
    "X = np.random.randn(M, C)\n",
    "\n",
    "# One-hot encoded labels (Y)\n",
    "target_classes = np.random.randint(0, C, M)\n",
    "Y = np.eye(C)[target_classes]\n",
    "\n",
    "# 3. Forward Pass\n",
    "P = softmax(X)\n",
    "loss = cross_entropy_loss(P, Y)\n",
    "\n",
    "# 4. Backward Pass\n",
    "grad_X = compute_gradients(P, Y)\n",
    "\n",
    "# --- Output Results ---\n",
    "print(f\"--- Forward Pass ---\")\n",
    "print(f\"Loss: {loss:.6f}\")\n",
    "print(f\"\\n--- Probabilities (P) Matrix (Shape {P.shape}) ---\")\n",
    "print(P[:3])  # Showing first 3 samples for brevity\n",
    "\n",
    "print(f\"\\n--- Gradient (dL/dX) Matrix (Shape {grad_X.shape}) ---\")\n",
    "print(grad_X[:3]) # Showing first 3 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "80a02d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(x):\n",
    "    \"\"\"x is the gradient from the next layer\n",
    "    retruns the gradients of the current layer\n",
    "    A VECTORIZED IMPLEMENATION FOR SOFTMAX GRADIENTS\n",
    "    \"\"\"\n",
    "    M, C = x.shape # number of examples, number of classes\n",
    "    diag_matrix = (x.reshape(M, C, 1) * np.eye(C))\n",
    "    outer_mult = (x.reshape(M, 1, C) @ x.reshape(M, C, 1))\n",
    "    J = diag_matrix - outer_mult\n",
    "    return J\n",
    "def backward(cache, grad_output):\n",
    "    J = gradient(cache)\n",
    "    M, C, _ = J.shape\n",
    "    return (grad_output.reshape(M, C, 1) @ J).squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fed54c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.31331809, -0.33723358, -0.301596  , -0.08757139],\n",
       "       [-0.39050547, -0.39050519, -0.07990173, -0.33607045],\n",
       "       [-0.28891095, -0.09098416, -0.28854375, -0.28868445],\n",
       "       [-0.08038469, -0.42048138, -0.41836377, -0.35610023],\n",
       "       [-0.37038081, -0.06251469, -0.36494715, -0.38320054],\n",
       "       [-0.04436242, -0.48133312, -0.46908024, -0.49529389],\n",
       "       [-0.28807808, -0.21235024, -0.30772729, -0.13995857],\n",
       "       [-0.61439713, -0.61058852, -0.61440663, -0.0171625 ],\n",
       "       [-0.35338446, -0.40930516, -0.07744079, -0.41150639],\n",
       "       [-0.19282963, -0.37659824, -0.3704244 , -0.19724616]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(P.reshape(10, 1, 4) @ ((P.reshape(10, 1, 4) * np.eye(4)) - (P.reshape(10, 1, 4) @ P.reshape(10, 4, 1)))).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5886b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mathematical Equivalence Match: True\n",
      "Difference (Max Absolute Error): 1.0245693182753257e-12\n",
      "\n",
      "--- Performance (M=10, C=3) ---\n",
      "Generalized Approach: 0.00169s\n",
      "Specialized Approach: 0.00074s\n",
      "Speedup: 2.3x\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1c69ba89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.        , -0.        , -0.12628734],\n",
       "       [-0.        , -0.48383658, -0.        ],\n",
       "       [-0.        , -0.28469443, -0.        ],\n",
       "       [-0.2882289 , -0.        , -0.        ],\n",
       "       [-0.        , -0.        , -0.70951207],\n",
       "       [-0.        , -0.        , -0.67888091],\n",
       "       [-0.        , -0.        , -0.2588631 ],\n",
       "       [-0.1952421 , -0.        , -0.        ],\n",
       "       [-0.35236601, -0.        , -0.        ],\n",
       "       [-0.        , -0.10617854, -0.        ]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_L_wrt_P_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1fa9e8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01331638,  0.00749912, -0.0208155 ],\n",
       "       [ 0.04639212, -0.07933186,  0.03293975],\n",
       "       [ 0.00991395, -0.06487462,  0.05496067],\n",
       "       [-0.06530535,  0.03492383,  0.03038153],\n",
       "       [ 0.05176686,  0.03413894, -0.08590581],\n",
       "       [ 0.06668133,  0.01858855, -0.08526988],\n",
       "       [ 0.0545415 ,  0.00682804, -0.06136954],\n",
       "       [-0.04878154,  0.01348676,  0.03529477],\n",
       "       [-0.07162042,  0.02376709,  0.04785333],\n",
       "       [ 0.00453173, -0.00581901,  0.00128728]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specialized_backward(P_large, Y_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0496e203",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[90]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP_large\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_L_wrt_P_large\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[89]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(cache, grad_output)\u001b[39m\n\u001b[32m     12\u001b[39m J = gradient(cache)\n\u001b[32m     13\u001b[39m M, C, _ = J.shape\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mgrad_output\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mJ\u001b[49m).squeeze(-\u001b[32m1\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 1)"
     ]
    }
   ],
   "source": [
    "backward(P_large, grad_L_wrt_P_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac970d15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
